{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6czvz5VKO5M"
      },
      "source": [
        "# Notebook for Programming in Problem 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o8HI5JqTvU5"
      },
      "source": [
        "## Learning Objectives\n",
        "In this problem, we will use [PyTorch](https://pytorch.org/) to implement long short-term memory (LSTM) for named entity recognition (NER). We will use the same dataset and boilerplate code as in Programming Problem 1 of Assignment #3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObrHyvWvTyGZ"
      },
      "source": [
        "## Writing Code\n",
        "Look for the keyword \"TODO\" and fill in your code in the empty space.\n",
        "Feel free to change function signatures, but be careful that you might need to also change how they are called in other parts of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r6YTnpgbFdMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6d7165e-11a2-4ad7-d83c-2130b469472e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 19 20:20:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi # you may need to try reconnecting to get a T4 gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnYMKJlKNXYe"
      },
      "source": [
        "## Installing PyTorch and Other Packages\n",
        "\n",
        "Install PyTorch using pip. See [https://pytorch.org/](https://pytorch.org/) if you want to install it on your computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-dRVuiP_JVdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ba7695-6952-4ff4-fb41-bc7d83c2eefa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.25.2)\n",
            "Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1->torchtext) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchtext -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPsFH637OpLy"
      },
      "source": [
        "Test if our installation works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c62StNb2NvKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11279c7c-e7a8-452b-df64-01d64ca018eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch successfully installed!\n",
            "Version: 2.2.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Multiply two matrices on GPU\n",
        "a = torch.rand(100, 200).cuda()\n",
        "b = torch.rand(200, 100).cuda()\n",
        "c = torch.matmul(a, b)\n",
        "\n",
        "print(\"PyTorch successfully installed!\")\n",
        "print(\"Version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qaC8sxcqkGX"
      },
      "source": [
        "Also install [scikit-learn](https://scikit-learn.org/stable/). We will use it for calculating evaluation metrics such as accuracy and F1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i5Y2xB_uqqM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374bbe32-0f9c-4aa0-ed61-1b381fc3b5e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhV4CYivRbt4"
      },
      "source": [
        "Let's import all the packages at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EjRM4cCFRh-d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.vocab import Vocab, vocab\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import re\n",
        "from collections import Counter\n",
        "from typing import List, Tuple, Dict, Optional, Any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn1bIPjAN-9V"
      },
      "source": [
        "## Long Short Term Memory (LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJOKIneRTrTH"
      },
      "source": [
        "### Data Loading\n",
        "\n",
        "We will use the same dataset for named entity recognition in Assignment #2. First download the data and take a look at the first 50 lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lWqz7kDxSqeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca47895d-5473-4a6b-f674-3ea3f572c479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU NNP I-NP ORG\n",
            "rejects VBZ I-VP O\n",
            "German JJ I-NP MISC\n",
            "call NN I-NP O\n",
            "to TO I-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ I-NP MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP I-NP PER\n",
            "Blackburn NNP I-NP PER\n",
            "\n",
            "BRUSSELS NNP I-NP LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT I-NP O\n",
            "European NNP I-NP ORG\n",
            "Commission NNP I-NP ORG\n",
            "said VBD I-VP O\n",
            "on IN I-PP O\n",
            "Thursday NNP I-NP O\n",
            "it PRP B-NP O\n",
            "disagreed VBD I-VP O\n",
            "with IN I-PP O\n",
            "German JJ I-NP MISC\n",
            "advice NN I-NP O\n",
            "to TO I-PP O\n",
            "consumers NNS I-NP O\n",
            "to TO I-VP O\n",
            "shun VB I-VP O\n",
            "British JJ I-NP MISC\n",
            "lamb NN I-NP O\n",
            "until IN I-SBAR O\n",
            "scientists NNS I-NP O\n",
            "determine VBP I-VP O\n",
            "whether IN I-SBAR O\n",
            "mad JJ I-NP O\n",
            "cow NN I-NP O\n",
            "disease NN I-NP O\n",
            "can MD I-VP O\n",
            "be VB I-VP O\n",
            "transmitted VBN I-VP O\n",
            "to TO I-PP O\n",
            "sheep NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Germany NNP I-NP LOC\n",
            "'s POS B-NP O\n",
            "representative NN I-NP O\n"
          ]
        }
      ],
      "source": [
        "!wget --quiet https://princeton-nlp.github.io/cos484/assignments/a2/eng.train\n",
        "!wget --quiet https://princeton-nlp.github.io/cos484/assignments/a2/eng.val\n",
        "!cat eng.train | head -n 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVt1a6nzWsiF"
      },
      "source": [
        "Each line corresponds to a word. Different sentences are separated by an additional line break. Take \"EU NNP I-NP ORG\" as an example. \"EU\" is a word. \"NNP\" and \"I-NP\" are tags for POS tagging and chunking, which we will ignore. \"ORG\" is the tag for NER, which is our prediction target. There are 5 possible values for the NER tag: ORG, PER, LOC, MISC, and O.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WnNfOBUYJvVW"
      },
      "outputs": [],
      "source": [
        "# A sentence is a list of (word, tag) tuples.\n",
        "# For example, [(\"hello\", \"O\"), (\"world\", \"O\"), (\"!\", \"O\")]\n",
        "Sentence = List[Tuple[str, str]]\n",
        "\n",
        "\n",
        "def read_data_file(\n",
        "    datapath: str,\n",
        ") -> Tuple[List[Sentence], Dict[str, int], Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Read and preprocess input data from the file `datapath`.\n",
        "    Example:\n",
        "    ```\n",
        "        sentences, word_cnt, tag_cnt = read_data_file(\"eng.train\")\n",
        "    ```\n",
        "    Return values:\n",
        "        `sentences`: a list of sentences, including words and NER tags\n",
        "        `word_cnt`: a Counter object, the number of occurrences of each word\n",
        "        `tag_cnt`: a Counter object, the number of occurences of each NER tag\n",
        "    \"\"\"\n",
        "    sentences: List[Sentence] = []\n",
        "    word_cnt: Dict[str, int] = Counter()\n",
        "    tag_cnt: Dict[str, int] = Counter()\n",
        "\n",
        "    for sentence_txt in open(datapath).read().split(\"\\n\\n\"):\n",
        "        if \"DOCSTART\" in sentence_txt:\n",
        "            # Ignore dummy sentences at the begining of each document.\n",
        "            continue\n",
        "        # Read a new sentence\n",
        "        sentences.append([])\n",
        "        for token in sentence_txt.split(\"\\n\"):\n",
        "            w, _, _, t = token.split()\n",
        "            # Replace all digits with \"0\" to reduce out-of-vocabulary words\n",
        "            w = re.sub(\"\\d\", \"0\", w)\n",
        "            word_cnt[w] += 1\n",
        "            tag_cnt[t] += 1\n",
        "            sentences[-1].append((w, t))\n",
        "\n",
        "    return sentences, word_cnt, tag_cnt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WLMGYSZ7KxzP"
      },
      "outputs": [],
      "source": [
        "# Some helper code\n",
        "def get_device() -> torch.device:\n",
        "    \"\"\"\n",
        "    Use GPU when it is available; use CPU otherwise.\n",
        "    See https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code\n",
        "    \"\"\"\n",
        "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wVHAOb7iMPwC"
      },
      "outputs": [],
      "source": [
        "def eval_metrics(ground_truth: List[int], predictions: List[int]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calculate various evaluation metrics such as accuracy and F1 score\n",
        "    Parameters:\n",
        "        `ground_truth`: the list of ground truth NER tags\n",
        "        `predictions`: the list of predicted NER tags\n",
        "    \"\"\"\n",
        "    f1_scores = f1_score(ground_truth, predictions, average=None)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(ground_truth, predictions),\n",
        "        \"f1\": f1_scores,\n",
        "        \"average f1\": np.mean(f1_scores),\n",
        "        \"confusion matrix\": confusion_matrix(ground_truth, predictions),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s830dhbnj1L"
      },
      "source": [
        "## Long Short-term Memory (LSTM)\n",
        "\n",
        "Now we implement an one-layer LSTM for the same task and compare it to FFNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to7DnWNiY5ZS"
      },
      "source": [
        "### Data Loading **(4 points)**\n",
        "\n",
        "Like before, we first implement the data loader. But unlike before, each data example is now a variable-length sentence. How can we pack multiple sentences with different lengths into the same batch? One possible solution is to pad them to the same length using a special token. The code below illustrates the idea:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "J5oVgqE7JaJp"
      },
      "outputs": [],
      "source": [
        "# 3 sentences with different lengths\n",
        "sentence_1 = torch.tensor([6, 1, 2])\n",
        "sentence_2 = torch.tensor([4, 2, 7, 7, 9])\n",
        "sentence_3 = torch.tensor([3, 4])\n",
        "# Form a batch by padding 0\n",
        "sentence_batch = torch.tensor([\n",
        "    [6, 1, 2, 0, 0],\n",
        "    [4, 2, 7, 7, 9],\n",
        "    [3, 4, 0, 0, 0],\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udC0SMjkKaCN"
      },
      "source": [
        "We implement the above idea in a customized batching function `form_batch`. Optionally, see [here](https://pytorch.org/docs/stable/data.html#loading-batched-and-non-batched-data) for how batching works in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sACcGN4XYMgj"
      },
      "outputs": [],
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Each data example is a sentence, including its words and NER tags.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, datapath: str, words_vocab: Optional[Vocab] = None, tags_vocab: Optional[Vocab] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the dataset by reading from datapath.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.sentences: List[Sentence] = []\n",
        "        UNKNOWN = \"<UNKNOWN>\"\n",
        "        PAD = \"<PAD>\"  # Special token used for padding\n",
        "\n",
        "        print(\"Loading data from %s\" % datapath)\n",
        "        self.sentences, word_cnt, tag_cnt = read_data_file(datapath)\n",
        "        print(\"%d sentences loaded.\" % len(self.sentences))\n",
        "\n",
        "        if words_vocab is None:\n",
        "            words_vocab = vocab(word_cnt, specials=[PAD, UNKNOWN])\n",
        "            words_vocab.set_default_index(words_vocab[UNKNOWN])\n",
        "\n",
        "        self.words_vocab = words_vocab\n",
        "\n",
        "        self.unknown_idx = self.words_vocab[UNKNOWN]\n",
        "        self.pad_idx = self.words_vocab[PAD]\n",
        "\n",
        "        if tags_vocab is None:\n",
        "            tags_vocab = vocab(tag_cnt, specials=[])\n",
        "        self.tags_vocab = tags_vocab\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Sentence:\n",
        "        \"\"\"\n",
        "        Get the idx'th sentence in the dataset.\n",
        "        \"\"\"\n",
        "        return self.sentences[idx]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Return the number of sentences in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def form_batch(self, sentences: List[Sentence]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        A customized function for batching a number of sentences together.\n",
        "        Different sentences have different lengths. Let max_len be the longest length.\n",
        "        When packing them into one tensor, we need to pad all sentences to max_len.\n",
        "        Return values:\n",
        "            `words`: a list in which each element itself is a list of words in a sentence\n",
        "            `word_idxs`: a batch_size x max_len tensor.\n",
        "                      word_idxs[i][j] is the index of the j'th word in the i'th sentence .\n",
        "            `tags`: a list in which each element itself is a list of tags in a sentence\n",
        "            `tag_idxs`: a batch_size x max_len tensor\n",
        "                      tag_idxs[i][j] is the index of the j'th tag in the i'th sentence.\n",
        "            `valid_mask`: a batch_size x max_len tensor\n",
        "                        valid_mask[i][j] is True if the i'th sentence has the j'th word.\n",
        "                        Otherwise, valid[i][j] is False.\n",
        "        \"\"\"\n",
        "        words: List[List[str]] = []\n",
        "        tags: List[List[str]] = []\n",
        "        max_len = -1  # length of the longest sentence\n",
        "        for sent in sentences:\n",
        "            words.append([])\n",
        "            tags.append([])\n",
        "            for w, t in sent:\n",
        "                words[-1].append(w)\n",
        "                tags[-1].append(t)\n",
        "            max_len = max(max_len, len(words[-1]))\n",
        "\n",
        "        batch_size = len(sentences)\n",
        "        word_idxs = torch.full(\n",
        "            (batch_size, max_len), fill_value=self.pad_idx, dtype=torch.int64\n",
        "        )\n",
        "        tag_idxs = torch.full_like(word_idxs, fill_value=self.tags_vocab[\"O\"])\n",
        "        valid_mask = torch.zeros_like(word_idxs, dtype=torch.bool)\n",
        "\n",
        "        for i, (word_list, tag_list) in enumerate(zip(words, tags)):\n",
        "            for j, (word, tag) in enumerate(zip(word_list, tag_list)):\n",
        "                word_idxs[i][j] = self.words_vocab[word]\n",
        "                tag_idxs[i][j] = self.tags_vocab[tag]\n",
        "                valid_mask[i][j] = True\n",
        "\n",
        "        return {\n",
        "            \"words\": words,\n",
        "            \"word_idxs\": word_idxs,\n",
        "            \"tags\": tags,\n",
        "            \"tag_idxs\": tag_idxs,\n",
        "            \"valid_mask\": valid_mask,\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "def create_sequence_dataloaders(\n",
        "    batch_size: int, shuffle: bool = True\n",
        ") -> Tuple[DataLoader, DataLoader, Vocab]:\n",
        "    \"\"\"\n",
        "    Create the dataloaders for training and validaiton.\n",
        "    \"\"\"\n",
        "    ds_train = SequenceDataset(\"eng.train\")\n",
        "    ds_val = SequenceDataset(\"eng.val\", words_vocab=ds_train.words_vocab, tags_vocab=ds_train.tags_vocab)\n",
        "    loader_train = DataLoader(\n",
        "        ds_train,\n",
        "        batch_size,\n",
        "        shuffle,\n",
        "        collate_fn=ds_train.form_batch,  # customized function for batching\n",
        "        drop_last=True,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    loader_val = DataLoader(\n",
        "        ds_val, batch_size, collate_fn=ds_val.form_batch, pin_memory=True\n",
        "    )\n",
        "    return loader_train, loader_val, ds_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2EcVxYuYvGv"
      },
      "source": [
        "Here is a simple sanity-check. Try to understand its output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TazmodGWYx2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f650fb6-28a0-47f8-e308-81baf3145180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from eng.train\n",
            "14041 sentences loaded.\n",
            "Loading data from eng.val\n",
            "3490 sentences loaded.\n",
            "Iterating on the training data..\n",
            "{'words': [['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], ['Peter', 'Blackburn'], ['BRUSSELS', '0000-00-00']], 'word_idxs': tensor([[ 2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
            "        [11, 12,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [13, 14,  0,  0,  0,  0,  0,  0,  0]]), 'tags': [['ORG', 'O', 'MISC', 'O', 'O', 'O', 'MISC', 'O', 'O'], ['PER', 'PER'], ['LOC', 'O']], 'tag_idxs': tensor([[0, 1, 2, 1, 1, 1, 2, 1, 1],\n",
            "        [3, 3, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [4, 1, 1, 1, 1, 1, 1, 1, 1]]), 'valid_mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [ True,  True, False, False, False, False, False, False, False],\n",
            "        [ True,  True, False, False, False, False, False, False, False]])}\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "def check_sequence_dataloader() -> None:\n",
        "    loader_train, _, _ = create_sequence_dataloaders(batch_size=3, shuffle=False)\n",
        "    print(\"Iterating on the training data..\")\n",
        "    for i, data_batch in enumerate(loader_train):\n",
        "        if i == 0:\n",
        "            print(data_batch)\n",
        "    print(\"Done!\")\n",
        "\n",
        "\n",
        "check_sequence_dataloader()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifk3i-obY8YB"
      },
      "source": [
        "### Implement the Model **(8 points)**\n",
        "\n",
        "Next, implement LSTM for predicting NER tags from input words. [nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) is definitely useful. Further, it is tricky to handle sentences in the same batch with different lengths. Please read the PyTorch documentation in detail!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3V0NvQynZF8e"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Long short-term memory for NER\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, words_vocab: Vocab, tags_vocab: Vocab, d_emb: int, d_hidden: int, bidirectional: bool) -> None:\n",
        "        \"\"\"\n",
        "        Initialize an LSTM\n",
        "        Parameters:\n",
        "            `words_vocab`: vocabulary of words\n",
        "            `tags_vocab`: vocabulary of tags\n",
        "            `d_emb`: dimension of word embeddings (D)\n",
        "            `d_hidden`: dimension of the hidden layer (H)\n",
        "            `bidirectional`: true if LSTM should be bidirectional\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.words_vocab = words_vocab\n",
        "        self.tags_vocab = tags_vocab\n",
        "        self.d_hidden = d_hidden\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # Create word embeddings\n",
        "        self.embedding = nn.Embedding(len(words_vocab), d_emb)  #creates an embedding layer that maps words to dense vectors of size d_emb.\n",
        "\n",
        "        # Create LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            d_emb, d_hidden, batch_first=True, bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        # Create output layer\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        self.hidden2tag = nn.Linear(d_hidden * num_directions, len(tags_vocab))\n",
        "\n",
        "    def forward(\n",
        "        self, word_idxs: torch.Tensor, valid_mask: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Given words in sentences, predict the logits of the NER tag.\n",
        "        Parameters:\n",
        "            `word_idxs`: a batch_size x max_len tensor\n",
        "            `valid_mask`: a batch_size x max_len tensor\n",
        "        Return values:\n",
        "            `logits`: a batch_size x max_len x 5 tensor\n",
        "        \"\"\"\n",
        "        # Get embeddings for words\n",
        "        embeddings = self.embedding(word_idxs) # retrieves the embeddings for the input word indices.\n",
        "\n",
        "        # Pack padded sequence\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(\n",
        "            embeddings, valid_mask.sum(1).tolist(), batch_first=True, enforce_sorted=False\n",
        "        )  # packs the padded input sequences to be compatible with the variable-length sequences in the batch.\n",
        "\n",
        "        # Run LSTM\n",
        "        packed_output, _ = self.lstm(packed_input)\n",
        "\n",
        "        # Unpack packed sequence\n",
        "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(\n",
        "            packed_output, batch_first=True\n",
        "        )  # unpacks the LSTM output to recover the padded sequences.\n",
        "\n",
        "        # Get logits\n",
        "        logits = self.hidden2tag(lstm_out) # passes the LSTM output through the output layer to get the logits for each tag.\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BFTKaB4Zydx"
      },
      "source": [
        "We do a sanity-check by loading a batch of data examples and pass it through the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PKg1ni4QZ6D1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2254ade9-ebc6-4328-8c33-0e5b69b5cb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from eng.train\n",
            "14041 sentences loaded.\n",
            "Loading data from eng.val\n",
            "3490 sentences loaded.\n",
            "LSTM(\n",
            "  (words_vocab): Vocab()\n",
            "  (tags_vocab): Vocab()\n",
            "  (embedding): Embedding(20102, 64)\n",
            "  (lstm): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=256, out_features=5, bias=True)\n",
            ")\n",
            "Input word_idxs shape: torch.Size([4, 10])\n",
            "Input valid_mask shape: torch.Size([4, 10])\n",
            "Output logits shape: torch.Size([4, 10, 5])\n"
          ]
        }
      ],
      "source": [
        "def check_lstm() -> None:\n",
        "    # Hyperparameters\n",
        "    batch_size = 4\n",
        "    d_emb = 64\n",
        "    d_hidden = 128\n",
        "    bidirectional = True\n",
        "    # Create the dataloaders and the model\n",
        "    loader_train, _, ds_train = create_sequence_dataloaders(batch_size)\n",
        "    model = LSTM(ds_train.words_vocab, ds_train.tags_vocab, d_emb, d_hidden, bidirectional)\n",
        "    device = get_device()\n",
        "    model.to(device)\n",
        "    print(model)\n",
        "    # Get the first batch\n",
        "    data_batch = next(iter(loader_train))\n",
        "    # Move data to GPU\n",
        "    word_idxs = data_batch[\"word_idxs\"].to(device, non_blocking=True)\n",
        "    tag_idxs = data_batch[\"tag_idxs\"].to(device, non_blocking=True)\n",
        "    valid_mask = data_batch[\"valid_mask\"].to(device, non_blocking=True)\n",
        "    # Calculate the model\n",
        "    print(\"Input word_idxs shape:\", word_idxs.size())\n",
        "    print(\"Input valid_mask shape:\", valid_mask.size())\n",
        "    logits = model(word_idxs, valid_mask)\n",
        "    print(\"Output logits shape:\", logits.size())\n",
        "\n",
        "\n",
        "check_lstm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jddDYUiLY-hc"
      },
      "source": [
        "### Training and Validation **(6 points)**\n",
        "\n",
        "Complete the functions for training and validating the LSTM model. When calculating the loss function, you only want to include values from valid positions (where `valid_mask` is `True`). The `reduction` parameter in [F.cross_entropy](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.cross_entropy) may be useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hv_15mnXZ_dy"
      },
      "outputs": [],
      "source": [
        "def train_lstm(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    optimizer: optim.Optimizer,\n",
        "    device: torch.device,\n",
        "    silent: bool = False,  # whether to print the training loss\n",
        ") -> Tuple[float, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Train the LSTM model.\n",
        "    Return values:\n",
        "        1. the average training loss\n",
        "        2. training metrics such as accuracy and F1 score\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    ground_truth = []\n",
        "    predictions = []\n",
        "    losses = []\n",
        "    report_interval = 100\n",
        "\n",
        "    for i, data_batch in enumerate(loader):\n",
        "        word_idxs = data_batch[\"word_idxs\"].to(device, non_blocking=True)\n",
        "        tag_idxs = data_batch[\"tag_idxs\"].to(device, non_blocking=True)\n",
        "        valid_mask = data_batch[\"valid_mask\"].to(device, non_blocking=True)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(word_idxs, valid_mask)\n",
        "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), tag_idxs.view(-1), ignore_index=-1, reduction='mean')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # we get (unmasked) predictions by getting argmax of logits along last dimension\n",
        "        net_predictions = torch.argmax(logits, -1)\n",
        "\n",
        "        # flattening tensors for ease of processing\n",
        "        tag_idxs_flat = tag_idxs.flatten()\n",
        "        valid_mask_flat = valid_mask.flatten()\n",
        "        net_predictions_flat = net_predictions.flatten()\n",
        "\n",
        "        ground_truth.extend(tag_idxs_flat[valid_mask_flat].tolist())\n",
        "        predictions.extend(net_predictions_flat[valid_mask_flat].tolist())\n",
        "\n",
        "        if not silent and i > 0 and i % report_interval == 0:\n",
        "            print(\n",
        "                \"\\t[%06d/%06d] Loss: %f\"\n",
        "                % (i, len(loader), np.mean(losses[-report_interval:]))\n",
        "            )\n",
        "\n",
        "    return np.mean(losses), eval_metrics(ground_truth, predictions)\n",
        "\n",
        "\n",
        "def validate_lstm(\n",
        "    model: nn.Module, loader: DataLoader, device: torch.device\n",
        ") -> Tuple[float, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Validate the model.\n",
        "    Return the validation loss and metrics.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    ground_truth = []\n",
        "    predictions = []\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for data_batch in loader:\n",
        "            word_idxs = data_batch[\"word_idxs\"].to(device, non_blocking=True)\n",
        "            tag_idxs = data_batch[\"tag_idxs\"].to(device, non_blocking=True)\n",
        "            valid_mask = data_batch[\"valid_mask\"].to(device, non_blocking=True)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(word_idxs, valid_mask)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), tag_idxs.view(-1), ignore_index=-1, reduction='mean')\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # we get (unmasked) predictions by getting argmax of logits\n",
        "            net_predictions = torch.argmax(logits, -1)\n",
        "\n",
        "            # flattening tensors for ease of processing\n",
        "            tag_idxs_flat = tag_idxs.flatten()\n",
        "            valid_mask_flat = valid_mask.flatten()\n",
        "            net_predictions_flat = net_predictions.flatten()\n",
        "\n",
        "            ground_truth.extend(tag_idxs_flat[valid_mask_flat].tolist())\n",
        "            predictions.extend(net_predictions_flat[valid_mask_flat].tolist())\n",
        "\n",
        "    return np.mean(losses), eval_metrics(ground_truth, predictions)\n",
        "\n",
        "\n",
        "def train_val_loop_lstm(hyperparams: Dict[str, Any]) -> None:\n",
        "    \"\"\"\n",
        "    Train and validate the LSTM model for a number of epochs.\n",
        "    \"\"\"\n",
        "    print(\"Hyperparameters:\", hyperparams)\n",
        "    # Create the dataloaders\n",
        "    loader_train, loader_val, ds_train = create_sequence_dataloaders(\n",
        "        hyperparams[\"batch_size\"]\n",
        "    )\n",
        "    # Create the model\n",
        "    model = LSTM(\n",
        "        ds_train.words_vocab,\n",
        "        ds_train.tags_vocab,\n",
        "        hyperparams[\"d_emb\"],\n",
        "        hyperparams[\"d_hidden\"],\n",
        "        hyperparams[\"bidirectional\"],\n",
        "    )\n",
        "    device = get_device()\n",
        "    model.to(device)\n",
        "    print(model)\n",
        "    # Create the optimizer\n",
        "    optimizer = optim.RMSprop(\n",
        "        model.parameters(), hyperparams[\"learning_rate\"], weight_decay=hyperparams[\"l2\"]\n",
        "    )\n",
        "\n",
        "    # Train and validate\n",
        "    for i in range(hyperparams[\"num_epochs\"]):\n",
        "        print(\"Epoch #%d\" % i)\n",
        "\n",
        "        print(\"Training..\")\n",
        "        loss_train, metrics_train = train_lstm(model, loader_train, optimizer, device)\n",
        "        print(\"Training loss: \", loss_train)\n",
        "        print(\"Training metrics:\")\n",
        "        for k, v in metrics_train.items():\n",
        "            print(\"\\t\", k, \": \", v)\n",
        "\n",
        "        print(\"Validating..\")\n",
        "        loss_val, metrics_val = validate_lstm(model, loader_val, device)\n",
        "        print(\"Validation loss: \", loss_val)\n",
        "        print(\"Validation metrics:\")\n",
        "        for k, v in metrics_val.items():\n",
        "            print(\"\\t\", k, \": \", v)\n",
        "\n",
        "    print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU9Nef7yal_M"
      },
      "source": [
        "Run the experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pFxQxlokai6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f01f8d7-26f4-43d4-b029-b615658c95d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'bidirectional': True, 'batch_size': 512, 'd_emb': 64, 'd_hidden': 128, 'num_epochs': 15, 'learning_rate': 0.005, 'l2': 1e-06}\n",
            "Loading data from eng.train\n",
            "14041 sentences loaded.\n",
            "Loading data from eng.val\n",
            "3490 sentences loaded.\n",
            "LSTM(\n",
            "  (words_vocab): Vocab()\n",
            "  (tags_vocab): Vocab()\n",
            "  (embedding): Embedding(20102, 64)\n",
            "  (lstm): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=256, out_features=5, bias=True)\n",
            ")\n",
            "Epoch #0\n",
            "Training..\n",
            "Training loss:  1.0599884986877441\n",
            "Training metrics:\n",
            "\t accuracy :  0.8113815461346633\n",
            "\t f1 :  [0.27540188 0.89903684 0.07683073 0.30509622 0.42303543]\n",
            "\t average f1 :  0.3958802204444027\n",
            "\t confusion matrix :  [[  2270   6499    226    544    312]\n",
            " [  3708 154388   2845   5374    659]\n",
            " [   153   3603    320    243    191]\n",
            " [   318   7172    180   3155    169]\n",
            " [   185   4816    249    372   2549]]\n",
            "Validating..\n",
            "Validation loss:  0.8112484301839556\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9123375300493012\n",
            "\t f1 :  [0.52395458 0.96007937 0.39375929 0.6718162  0.70440252]\n",
            "\t average f1 :  0.65080239115473\n",
            "\t confusion matrix :  [[  946   935    38   200   131]\n",
            " [  126 40644    16   323    55]\n",
            " [   66   559   265    64    53]\n",
            " [  120   817     5  1696    52]\n",
            " [  103   549    15    76  1232]]\n",
            "Epoch #1\n",
            "Training..\n",
            "Training loss:  0.6979311726711415\n",
            "Training metrics:\n",
            "\t accuracy :  0.93672900319747\n",
            "\t f1 :  [0.67675315 0.97352118 0.62627894 0.76777897 0.79158225]\n",
            "\t average f1 :  0.7671828987136883\n",
            "\t confusion matrix :  [[  5882   2594    266    635    497]\n",
            " [   433 165631    145    543    206]\n",
            " [   352   1411   2326    238    196]\n",
            " [   455   2357     66   7892    181]\n",
            " [   387   1321    102    299   6056]]\n",
            "Validating..\n",
            "Validation loss:  0.614547882761274\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9386790530904943\n",
            "\t f1 :  [0.70463511 0.97534267 0.67169374 0.75264338 0.81988892]\n",
            "\t average f1 :  0.7848407622219459\n",
            "\t confusion matrix :  [[ 1429   389    62   265   105]\n",
            " [  156 40169    48   709    82]\n",
            " [   50   232   579   106    40]\n",
            " [   74   228    10  2349    29]\n",
            " [   97   187    18   123  1550]]\n",
            "Epoch #2\n",
            "Training..\n",
            "Training loss:  0.5295592093909228\n",
            "Training metrics:\n",
            "\t accuracy :  0.9667553721644141\n",
            "\t f1 :  [0.82392551 0.98821669 0.7981444  0.89214047 0.87345038]\n",
            "\t average f1 :  0.8751754910693549\n",
            "\t confusion matrix :  [[  7831   1074    226    381    379]\n",
            " [   326 166264    134    275    131]\n",
            " [   282    630   3355    121    137]\n",
            " [   318    836     57   9603    144]\n",
            " [   361    559    110    190   6940]]\n",
            "Validating..\n",
            "Validation loss:  0.49584964343479704\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9443018375911665\n",
            "\t f1 :  [0.74831461 0.97783058 0.72257384 0.77126238 0.85422664]\n",
            "\t average f1 :  0.8148416100644693\n",
            "\t confusion matrix :  [[ 1665   220    62   223    80]\n",
            " [  250 39917    97   805    95]\n",
            " [   69   136   685    93    24]\n",
            " [   89   120    13  2453    15]\n",
            " [  127    87    32    97  1632]]\n",
            "Epoch #3\n",
            "Training..\n",
            "Training loss:  0.4217067945886541\n",
            "Training metrics:\n",
            "\t accuracy :  0.9823395262262278\n",
            "\t f1 :  [0.90275777 0.99424676 0.87563335 0.95149563 0.93021529]\n",
            "\t average f1 :  0.9308697602240462\n",
            "\t confusion matrix :  [[  8773    544    159    187    219]\n",
            " [   213 166421     73    112     70]\n",
            " [   176    361   3802     76    110]\n",
            " [   166    314     30  10338     69]\n",
            " [   226    239     95    100   7518]]\n",
            "Validating..\n",
            "Validation loss:  0.41295771087918964\n",
            "Validation metrics:\n",
            "\t accuracy :  0.946237216314224\n",
            "\t f1 :  [0.77059224 0.97834754 0.74868559 0.76918392 0.86560847]\n",
            "\t average f1 :  0.8264835529563843\n",
            "\t confusion matrix :  [[ 1698   201    50   234    67]\n",
            " [  218 39875    96   912    63]\n",
            " [   63   115   712    90    27]\n",
            " [   58    82    12  2526    12]\n",
            " [  120    78    25   116  1636]]\n",
            "Epoch #4\n",
            "Training..\n",
            "Training loss:  0.34255417298387597\n",
            "Training metrics:\n",
            "\t accuracy :  0.9898054769402479\n",
            "\t f1 :  [0.94124866 0.99681005 0.92579585 0.97582337 0.95762712]\n",
            "\t average f1 :  0.9594610117444905\n",
            "\t confusion matrix :  [[  9204    316     82     95    160]\n",
            " [   152 166867     49     50     34]\n",
            " [   113    209   4086     47     73]\n",
            " [    84    135     24  10696     41]\n",
            " [   147    123     58     54   7797]]\n",
            "Validating..\n",
            "Validation loss:  0.34863986713545664\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9507395183962841\n",
            "\t f1 :  [0.77937337 0.98021779 0.732      0.80941484 0.86776643]\n",
            "\t average f1 :  0.8337544857335054\n",
            "\t confusion matrix :  [[ 1791   183    59   159    58]\n",
            " [  267 40012   153   644    88]\n",
            " [   75   110   732    65    25]\n",
            " [   77   106    15  2476    16]\n",
            " [  136    64    34    84  1657]]\n",
            "Epoch #5\n",
            "Training..\n",
            "Training loss:  0.2854678410070914\n",
            "Training metrics:\n",
            "\t accuracy :  0.9945503271300885\n",
            "\t f1 :  [0.96649119 0.99840337 0.95763569 0.98942088 0.97674988]\n",
            "\t average f1 :  0.9777402036797703\n",
            "\t confusion matrix :  [[  9547    174     58     46     91]\n",
            " [    90 166648     29     21     17]\n",
            " [    77     91   4261     26     44]\n",
            " [    38     47     15  10849     17]\n",
            " [    88     64     37     22   7982]]\n",
            "Validating..\n",
            "Validation loss:  0.29845605151993887\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9536324002770648\n",
            "\t f1 :  [0.79586207 0.98109102 0.73135056 0.82286661 0.87331124]\n",
            "\t average f1 :  0.8408963014303186\n",
            "\t confusion matrix :  [[ 1731   212    73   153    81]\n",
            " [  168 40133   171   578   114]\n",
            " [   54   120   750    59    24]\n",
            " [   61   111    19  2483    16]\n",
            " [   86    73    31    72  1713]]\n",
            "Epoch #6\n",
            "Training..\n",
            "Training loss:  0.24050042474711383\n",
            "Training metrics:\n",
            "\t accuracy :  0.9970470722619327\n",
            "\t f1 :  [0.98151721 0.99905704 0.97626741 0.99598063 0.9875153 ]\n",
            "\t average f1 :  0.9880675196363228\n",
            "\t confusion matrix :  [[  9665    107     33     22     52]\n",
            " [    47 166870     19      9     13]\n",
            " [    43     68   4381      8     21]\n",
            " [    13     14      5  10903     11]\n",
            " [    47     38     16      6   8068]]\n",
            "Validating..\n",
            "Validation loss:  0.2583920168025153\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9581550747667359\n",
            "\t f1 :  [0.8064207  0.98274018 0.74939173 0.85019524 0.87094377]\n",
            "\t average f1 :  0.851938323854841\n",
            "\t confusion matrix :  [[ 1683   267    76   111   113]\n",
            " [  104 40426   156   355   123]\n",
            " [   23   148   770    37    29]\n",
            " [   53   179    24  2395    39]\n",
            " [   61    88    22    46  1758]]\n",
            "Epoch #7\n",
            "Training..\n",
            "Training loss:  0.20671359366840786\n",
            "Training metrics:\n",
            "\t accuracy :  0.9924753049100384\n",
            "\t f1 :  [0.97481648 0.99641031 0.96292172 0.97065814 0.97883792]\n",
            "\t average f1 :  0.9767289131988115\n",
            "\t confusion matrix :  [[  9561    203     24     28     46]\n",
            " [   110 166129     77    268     72]\n",
            " [    22    142   4324     13     18]\n",
            " [    28    219     26  10619     44]\n",
            " [    33    106     11     16   8002]]\n",
            "Validating..\n",
            "Validation loss:  0.22067715653351375\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9616795012834617\n",
            "\t f1 :  [0.81998115 0.98417514 0.77008032 0.85920705 0.88675823]\n",
            "\t average f1 :  0.8640403777004122\n",
            "\t confusion matrix :  [[ 1740   253    65   113    79]\n",
            " [  102 40549   115   337    61]\n",
            " [   27   158   767    36    19]\n",
            " [   45   178    15  2438    14]\n",
            " [   80   100    23    61  1711]]\n",
            "Epoch #8\n",
            "Training..\n",
            "Training loss:  0.17398237961309929\n",
            "Training metrics:\n",
            "\t accuracy :  0.9975855872001275\n",
            "\t f1 :  [0.98758551 0.9989782  0.98272808 0.99530901 0.99240568]\n",
            "\t average f1 :  0.9914012956028948\n",
            "\t confusion matrix :  [[  9745     93     15     11     19]\n",
            " [    60 167180     28      9     15]\n",
            " [    17     63   4438     16      7]\n",
            " [     8     37      4  10927     12]\n",
            " [    22     37      6      6   8102]]\n",
            "Validating..\n",
            "Validation loss:  0.1951029066528593\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9630240801857963\n",
            "\t f1 :  [0.81756914 0.98473292 0.76394422 0.87405269 0.89257914]\n",
            "\t average f1 :  0.8665756210061837\n",
            "\t confusion matrix :  [[ 1759   259    63    97    72]\n",
            " [  117 40603   130   255    59]\n",
            " [   41   154   767    29    16]\n",
            " [   53   187    16  2422    12]\n",
            " [   83    98    25    49  1720]]\n",
            "Epoch #9\n",
            "Training..\n",
            "Training loss:  0.1491419286639602\n",
            "Training metrics:\n",
            "\t accuracy :  0.9990419974353473\n",
            "\t f1 :  [0.99443601 0.99961063 0.99213122 0.99871842 0.99724248]\n",
            "\t average f1 :  0.9964277524376725\n",
            "\t confusion matrix :  [[  9830     46      8      7     10]\n",
            " [    16 166872     11      3      3]\n",
            " [    11     32   4476      4      4]\n",
            " [     3      6      0  10910      4]\n",
            " [     9     13      1      1   8137]]\n",
            "Validating..\n",
            "Validation loss:  0.17555477789470128\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9639815833435196\n",
            "\t f1 :  [0.81701332 0.98494405 0.77219685 0.88126747 0.88918136]\n",
            "\t average f1 :  0.868920613378541\n",
            "\t confusion matrix :  [[ 1748   297    58    77    70]\n",
            " [   96 40756   102   170    40]\n",
            " [   36   176   761    21    13]\n",
            " [   54   243    17  2364    12]\n",
            " [   95   122    26    43  1689]]\n",
            "Epoch #10\n",
            "Training..\n",
            "Training loss:  0.12904354681571326\n",
            "Training metrics:\n",
            "\t accuracy :  0.9994312512472561\n",
            "\t f1 :  [0.99680738 0.99976937 0.99567484 0.9993595  0.99786624]\n",
            "\t average f1 :  0.9978954663532047\n",
            "\t confusion matrix :  [[  9835     27      5      3      8]\n",
            " [     8 166896      6      2      6]\n",
            " [     6     16   4489      0      3]\n",
            " [     3      2      1  10922      2]\n",
            " [     3     10      2      1   8184]]\n",
            "Validating..\n",
            "Validation loss:  0.15995327915464128\n",
            "Validation metrics:\n",
            "\t accuracy :  0.964205679827242\n",
            "\t f1 :  [0.81461762 0.98476092 0.78113788 0.8792813  0.89319886]\n",
            "\t average f1 :  0.8705993155841577\n",
            "\t confusion matrix :  [[ 1683   331    66    86    84]\n",
            " [   70 40808    82   157    47]\n",
            " [   24   181   762    23    17]\n",
            " [   45   266    13  2349    17]\n",
            " [   60   129    21    38  1727]]\n",
            "Epoch #11\n",
            "Training..\n",
            "Training loss:  0.11392135918140411\n",
            "Training metrics:\n",
            "\t accuracy :  0.9970680628272252\n",
            "\t f1 :  [0.97423576 0.99954211 0.99038993 0.99668227 0.97802534]\n",
            "\t average f1 :  0.9877750832010526\n",
            "\t confusion matrix :  [[  9529     74     31     45    166]\n",
            " [    27 166996      7      5      9]\n",
            " [     8     17   4483      2     12]\n",
            " [    12      1      0  10965      3]\n",
            " [   141     13     10      5   7989]]\n",
            "Validating..\n",
            "Validation loss:  0.14012185590607779\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9647761072403537\n",
            "\t f1 :  [0.82219599 0.98459313 0.79480519 0.88070579 0.89345114]\n",
            "\t average f1 :  0.8751502489154964\n",
            "\t confusion matrix :  [[ 1741   321    45    68    75]\n",
            " [   93 40836    73   107    55]\n",
            " [   25   181   765    24    12]\n",
            " [   52   315    15  2296    12]\n",
            " [   74   133    20    29  1719]]\n",
            "Epoch #12\n",
            "Training..\n",
            "Training loss:  0.09827401213071964\n",
            "Training metrics:\n",
            "\t accuracy :  0.9991627086375575\n",
            "\t f1 :  [0.99427761 0.99969182 0.99623227 0.99890431 0.99621951]\n",
            "\t average f1 :  0.9970651044080541\n",
            "\t confusion matrix :  [[  9817     32      4     11     17]\n",
            " [    29 167058      9      4      7]\n",
            " [     4     10   4495      0      5]\n",
            " [     3      0      0  10940      4]\n",
            " [    13     12      2      2   8169]]\n",
            "Validating..\n",
            "Validation loss:  0.131506441959313\n",
            "Validation metrics:\n",
            "\t accuracy :  0.964979831316465\n",
            "\t f1 :  [0.82170172 0.98426977 0.80042239 0.87965504 0.89791667]\n",
            "\t average f1 :  0.8767931164507281\n",
            "\t confusion matrix :  [[ 1719   353    46    53    79]\n",
            " [   76 40922    57    74    35]\n",
            " [   22   199   758    15    13]\n",
            " [   50   372    10  2244    14]\n",
            " [   67   142    16    26  1724]]\n",
            "Epoch #13\n",
            "Training..\n",
            "Training loss:  0.08532238668865627\n",
            "Training metrics:\n",
            "\t accuracy :  0.9997705392328029\n",
            "\t f1 :  [0.99868127 0.99990716 0.99889795 0.99968003 0.99889976]\n",
            "\t average f1 :  0.9992132340962785\n",
            "\t confusion matrix :  [[  9845     10      3      3      3]\n",
            " [     3 166941      0      0      4]\n",
            " [     0      6   4532      0      1]\n",
            " [     3      0      0  10935      1]\n",
            " [     1      8      0      0   8171]]\n",
            "Validating..\n",
            "Validation loss:  0.12154671443360192\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9651224381697429\n",
            "\t f1 :  [0.82425684 0.98436485 0.80251441 0.87764706 0.89926548]\n",
            "\t average f1 :  0.8776097261994964\n",
            "\t confusion matrix :  [[ 1733   344    47    58    68]\n",
            " [   73 40923    60    75    33]\n",
            " [   26   193   766    13     9]\n",
            " [   52   376    11  2238    13]\n",
            " [   71   146    18    26  1714]]\n",
            "Epoch #14\n",
            "Training..\n",
            "Training loss:  0.07509343574444453\n",
            "Training metrics:\n",
            "\t accuracy :  0.9998352940002097\n",
            "\t f1 :  [0.99893955 0.99993706 0.99911387 0.9996347  0.99951028]\n",
            "\t average f1 :  0.9994270938076275\n",
            "\t confusion matrix :  [[  9891      8      2      4      0]\n",
            " [     3 166813      0      0      2]\n",
            " [     0      4   4510      0      1]\n",
            " [     3      1      0  10946      0]\n",
            " [     1      3      1      0   8164]]\n",
            "Validating..\n",
            "Validation loss:  0.11551530552761895\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9644094039033533\n",
            "\t f1 :  [0.82623265 0.98364239 0.80929741 0.8695479  0.89779874]\n",
            "\t average f1 :  0.8773038180295799\n",
            "\t confusion matrix :  [[ 1726   354    44    52    74]\n",
            " [   72 40951    49    63    29]\n",
            " [   22   197   766    13     9]\n",
            " [   37   443    11  2183    16]\n",
            " [   71   155    16    20  1713]]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "train_val_loop_lstm({\n",
        "    \"bidirectional\": True,\n",
        "    \"batch_size\": 512,\n",
        "    \"d_emb\": 64,\n",
        "    \"d_hidden\": 128,\n",
        "    \"num_epochs\": 15,\n",
        "    \"learning_rate\": 0.005,\n",
        "    \"l2\": 1e-6,\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vA-Yjqg7n0V"
      },
      "source": [
        "We were using bidirectional LSTMs. Please re-run the experiment with a regular (unidirectional) LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7wNrdvJ98ARB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c01065-ee3c-4529-b6da-daa5070a8e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'bidirectional': False, 'batch_size': 512, 'd_emb': 64, 'd_hidden': 128, 'num_epochs': 15, 'learning_rate': 0.005, 'l2': 1e-06}\n",
            "Loading data from eng.train\n",
            "14041 sentences loaded.\n",
            "Loading data from eng.val\n",
            "3490 sentences loaded.\n",
            "LSTM(\n",
            "  (words_vocab): Vocab()\n",
            "  (tags_vocab): Vocab()\n",
            "  (embedding): Embedding(20102, 64)\n",
            "  (lstm): LSTM(64, 128, batch_first=True)\n",
            "  (hidden2tag): Linear(in_features=128, out_features=5, bias=True)\n",
            ")\n",
            "Epoch #0\n",
            "Training..\n",
            "Training loss:  1.0627086537855643\n",
            "Training metrics:\n",
            "\t accuracy :  0.8033637967131528\n",
            "\t f1 :  [0.02497464 0.89656871 0.0604483  0.25127404 0.24309525]\n",
            "\t average f1 :  0.29527218681033723\n",
            "\t confusion matrix :  [[   160   8287    193    400    822]\n",
            " [  2524 156540   1699   1220   4723]\n",
            " [    63   3708    209    176    364]\n",
            " [   117   8213    174   1849    529]\n",
            " [    87   5744    120    190   2020]]\n",
            "Validating..\n",
            "Validation loss:  0.8463542376245771\n",
            "Validation metrics:\n",
            "\t accuracy :  0.8821252495619932\n",
            "\t f1 :  [0.07539178 0.9437118  0.25       0.44129979 0.61385071]\n",
            "\t average f1 :  0.46485081840621856\n",
            "\t confusion matrix :  [[   89  1622    45   140   354]\n",
            " [    2 41076    10    28    48]\n",
            " [    7   673   154    49   124]\n",
            " [    5  1768     4   842    71]\n",
            " [    8   749    12    67  1139]]\n",
            "Epoch #1\n",
            "Training..\n",
            "Training loss:  0.7114442940111514\n",
            "Training metrics:\n",
            "\t accuracy :  0.9173506737012177\n",
            "\t f1 :  [0.48577377 0.96950177 0.50107991 0.70612385 0.68660566]\n",
            "\t average f1 :  0.6698169916115304\n",
            "\t confusion matrix :  [[  3850   3323    377    983   1361]\n",
            " [   396 165556    122    638    325]\n",
            " [   540   1326   1740    354    534]\n",
            " [   519   2819     74   7224    306]\n",
            " [   652   1467    138    320   5590]]\n",
            "Validating..\n",
            "Validation loss:  0.6401809539113726\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9250295399910361\n",
            "\t f1 :  [0.54062751 0.96924917 0.60884956 0.69140951 0.74078308]\n",
            "\t average f1 :  0.7101837657161736\n",
            "\t confusion matrix :  [[ 1008   784    84   209   165]\n",
            " [   76 40928    34   106    20]\n",
            " [   84   310   516    66    31]\n",
            " [   68   941    11  1658    12]\n",
            " [  243   326    43    67  1296]]\n",
            "Epoch #2\n",
            "Training..\n",
            "Training loss:  0.5441624180034355\n",
            "Training metrics:\n",
            "\t accuracy :  0.9556374127148126\n",
            "\t f1 :  [0.73117942 0.98698793 0.72266474 0.86433801 0.80892556]\n",
            "\t average f1 :  0.8228191315268484\n",
            "\t confusion matrix :  [[  6993   1183    398    503    795]\n",
            " [   384 165736    139    391    139]\n",
            " [   495    599   2994    161    278]\n",
            " [   483   1015     80   9267    124]\n",
            " [   901    520    148    152   6471]]\n",
            "Validating..\n",
            "Validation loss:  0.5182245246001652\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9379456464164935\n",
            "\t f1 :  [0.62102689 0.97354133 0.6955037  0.75763319 0.79454927]\n",
            "\t average f1 :  0.7684508748203411\n",
            "\t confusion matrix :  [[ 1143   676    68   126   237]\n",
            " [   68 40971    38    66    21]\n",
            " [   53   263   611    32    48]\n",
            " [   41   817    14  1799    19]\n",
            " [  126   278    19    36  1516]]\n",
            "Epoch #3\n",
            "Training..\n",
            "Training loss:  0.4329594506157769\n",
            "Training metrics:\n",
            "\t accuracy :  0.9724792633171702\n",
            "\t f1 :  [0.8260355  0.99290017 0.80771897 0.93176471 0.86910414]\n",
            "\t average f1 :  0.8855046977500427\n",
            "\t confusion matrix :  [[  8027    646    319    260    625]\n",
            " [   261 166070    125    174     78]\n",
            " [   345    374   3495     99    217]\n",
            " [   278    453     54  10098     70]\n",
            " [   647    264    131     91   7048]]\n",
            "Validating..\n",
            "Validation loss:  0.4339490234851837\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9447704029662225\n",
            "\t f1 :  [0.68485607 0.97578966 0.72707059 0.799319   0.8084989 ]\n",
            "\t average f1 :  0.7991068453368558\n",
            "\t confusion matrix :  [[ 1368   627    60    61   134]\n",
            " [   75 41010    29    37    13]\n",
            " [   58   253   654    12    30]\n",
            " [   57   732    16  1878     7]\n",
            " [  187   269    33    21  1465]]\n",
            "Epoch #4\n",
            "Training..\n",
            "Training loss:  0.35164532175770513\n",
            "Training metrics:\n",
            "\t accuracy :  0.981504598883485\n",
            "\t f1 :  [0.87719298 0.99570628 0.85773291 0.96356312 0.90524368]\n",
            "\t average f1 :  0.9198877934977274\n",
            "\t confusion matrix :  [[  8575    400    265    152    476]\n",
            " [   199 166387     76     77     48]\n",
            " [   267    258   3738     68    172]\n",
            " [   158    222     26  10525     33]\n",
            " [   484    155    108     60   7337]]\n",
            "Validating..\n",
            "Validation loss:  0.37468574728284565\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9444851892596667\n",
            "\t f1 :  [0.69483125 0.97618424 0.72645234 0.79758308 0.78880554]\n",
            "\t average f1 :  0.7967712910500638\n",
            "\t confusion matrix :  [[ 1472   593    46    49    90]\n",
            " [   78 41030    27    20     9]\n",
            " [   77   254   644    10    22]\n",
            " [   69   759    11  1848     3]\n",
            " [  291   262    38    17  1367]]\n",
            "Epoch #5\n",
            "Training..\n",
            "Training loss:  0.29349792445147477\n",
            "Training metrics:\n",
            "\t accuracy :  0.9864049770256584\n",
            "\t f1 :  [0.90653061 0.99700537 0.89259764 0.97801095 0.92700595]\n",
            "\t average f1 :  0.9402301049180487\n",
            "\t confusion matrix :  [[  8884    299    186    104    380]\n",
            " [   171 166632     65     43     38]\n",
            " [   207    201   3931     40    142]\n",
            " [   101     97     22  10719     30]\n",
            " [   384     87     83     45   7550]]\n",
            "Validating..\n",
            "Validation loss:  0.3216297839369093\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9487837672656154\n",
            "\t f1 :  [0.71464393 0.97725216 0.75110619 0.81268625 0.82498654]\n",
            "\t average f1 :  0.8161350138130473\n",
            "\t confusion matrix :  [[ 1425   581    54    49   141]\n",
            " [   64 41027    34    26    13]\n",
            " [   39   246   679     8    35]\n",
            " [   53   698    12  1909    18]\n",
            " [  157   248    22    16  1532]]\n",
            "Epoch #6\n",
            "Training..\n",
            "Training loss:  0.2466882919823682\n",
            "Training metrics:\n",
            "\t accuracy :  0.98973164637765\n",
            "\t f1 :  [0.92497713 0.99797414 0.91820936 0.98785499 0.94074527]\n",
            "\t average f1 :  0.9539521760082754\n",
            "\t confusion matrix :  [[  9099    230    161     61    318]\n",
            " [   134 166751     47     25     32]\n",
            " [   186    110   4092     23    119]\n",
            " [    53     45     14  10818     18]\n",
            " [   333     54     69     27   7700]]\n",
            "Validating..\n",
            "Validation loss:  0.2860921791621617\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9485189259666708\n",
            "\t f1 :  [0.70989583 0.97714708 0.73754494 0.81210055 0.83284613]\n",
            "\t average f1 :  0.8139069080038182\n",
            "\t confusion matrix :  [[ 1363   568    99    52   168]\n",
            " [   63 41005    58    23    15]\n",
            " [   23   234   718     6    26]\n",
            " [   41   715    16  1906    12]\n",
            " [  100   242    49    17  1567]]\n",
            "Epoch #7\n",
            "Training..\n",
            "Training loss:  0.20927489852463757\n",
            "Training metrics:\n",
            "\t accuracy :  0.9917219368673017\n",
            "\t f1 :  [0.93788757 0.99839646 0.93297587 0.99223809 0.95164929]\n",
            "\t average f1 :  0.9626294558474221\n",
            "\t confusion matrix :  [[  9226    188    147     39    290]\n",
            " [   123 166862     37      9     27]\n",
            " [   145     90   4176     14    102]\n",
            " [    47     22      6  10802     16]\n",
            " [   243     40     59     16   7804]]\n",
            "Validating..\n",
            "Validation loss:  0.2504625469446182\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9505357943201728\n",
            "\t f1 :  [0.73171937 0.97794907 0.75013912 0.82269798 0.8328841 ]\n",
            "\t average f1 :  0.823077928405338\n",
            "\t confusion matrix :  [[ 1481   542    46    56   125]\n",
            " [   80 40979    37    47    21]\n",
            " [   45   240   674    16    32]\n",
            " [   44   648     7  1979    12]\n",
            " [  148   233    26    23  1545]]\n",
            "Epoch #8\n",
            "Training..\n",
            "Training loss:  0.1793325256418299\n",
            "Training metrics:\n",
            "\t accuracy :  0.9920253991038542\n",
            "\t f1 :  [0.93849287 0.99850725 0.93945117 0.99326109 0.95118379]\n",
            "\t average f1 :  0.9641792353942067\n",
            "\t confusion matrix :  [[  9216    185    143     32    291]\n",
            " [   112 166892     34     11     27]\n",
            " [   131     71   4228     16     92]\n",
            " [    30     28      7  10907      9]\n",
            " [   284     31     51     15   7794]]\n",
            "Validating..\n",
            "Validation loss:  0.22483241770948684\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9511469665485067\n",
            "\t f1 :  [0.73165778 0.97781487 0.75440529 0.82370308 0.84274406]\n",
            "\t average f1 :  0.8260650150580705\n",
            "\t confusion matrix :  [[ 1441   550    51    48   160]\n",
            " [   70 41012    38    28    16]\n",
            " [   45   240   685     8    29]\n",
            " [   41   676     7  1953    13]\n",
            " [   92   243    28    15  1597]]\n",
            "Epoch #9\n",
            "Training..\n",
            "Training loss:  0.15394364573337413\n",
            "Training metrics:\n",
            "\t accuracy :  0.9938458776356999\n",
            "\t f1 :  [0.95351912 0.99871555 0.95244444 0.99553693 0.96350899]\n",
            "\t average f1 :  0.9727450070292066\n",
            "\t confusion matrix :  [[  9375    151    114     19    217]\n",
            " [   109 166783     34     13     22]\n",
            " [    92     58   4286      5     76]\n",
            " [    19     15      6  10930     10]\n",
            " [   193     27     43     11   7908]]\n",
            "Validating..\n",
            "Validation loss:  0.21485164548669541\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9479077537383368\n",
            "\t f1 :  [0.72336066 0.97547535 0.76137002 0.79204024 0.84029087]\n",
            "\t average f1 :  0.8185074258633087\n",
            "\t confusion matrix :  [[ 1412   626    48    37   127]\n",
            " [   46 41068    20    17    13]\n",
            " [   34   262   678     7    26]\n",
            " [   43   818     6  1811    12]\n",
            " [  119   263    22    11  1560]]\n",
            "Epoch #10\n",
            "Training..\n",
            "Training loss:  0.1373380392237946\n",
            "Training metrics:\n",
            "\t accuracy :  0.990511643668366\n",
            "\t f1 :  [0.95287    0.9968846  0.95079802 0.96826419 0.95711668]\n",
            "\t average f1 :  0.9651866975934181\n",
            "\t confusion matrix :  [[  9371    173    106     39    214]\n",
            " [   103 166713     40    225     52]\n",
            " [    62     72   4319     17     73]\n",
            " [    41    311     13  10526     20]\n",
            " [   189     66     64     24   7834]]\n",
            "Validating..\n",
            "Validation loss:  0.17776890311922347\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9512488285865623\n",
            "\t f1 :  [0.7286002  0.9781424  0.76045627 0.82876423 0.8343983 ]\n",
            "\t average f1 :  0.8260722816085118\n",
            "\t confusion matrix :  [[ 1447   558    53    39   153]\n",
            " [   73 41014    41    20    16]\n",
            " [   44   229   700     8    26]\n",
            " [   44   654     8  1965    19]\n",
            " [  114   242    32    20  1567]]\n",
            "Epoch #11\n",
            "Training..\n",
            "Training loss:  0.11637841937718568\n",
            "Training metrics:\n",
            "\t accuracy :  0.9946698607575984\n",
            "\t f1 :  [0.9609018  0.99888271 0.9608628  0.99445234 0.96828882]\n",
            "\t average f1 :  0.9766776919065128\n",
            "\t confusion matrix :  [[  9462    126     96     24    175]\n",
            " [    84 166735     34     10     21]\n",
            " [    70     41   4321      6     61]\n",
            " [    22     31      4  10845     13]\n",
            " [   173     26     40     11   7939]]\n",
            "Validating..\n",
            "Validation loss:  0.1647863941533225\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9506376563582284\n",
            "\t f1 :  [0.72835679 0.97840902 0.74958723 0.83171658 0.82255846]\n",
            "\t average f1 :  0.8221256149240916\n",
            "\t confusion matrix :  [[ 1527   522    44    39   118]\n",
            " [  106 40988    37    19    14]\n",
            " [   69   227   681     6    24]\n",
            " [   53   646    10  1972     9]\n",
            " [  188   238    38    16  1495]]\n",
            "Epoch #12\n",
            "Training..\n",
            "Training loss:  0.1009415848939507\n",
            "Training metrics:\n",
            "\t accuracy :  0.9957371703785692\n",
            "\t f1 :  [0.96707756 0.99914684 0.97058173 0.99676788 0.97317774]\n",
            "\t average f1 :  0.9813503498965019\n",
            "\t confusion matrix :  [[  9532    111     72     13    168]\n",
            " [    66 166884     23      6     17]\n",
            " [    57     34   4388      4     39]\n",
            " [    17     10      3  10948     11]\n",
            " [   145     18     34      7   7964]]\n",
            "Validating..\n",
            "Validation loss:  0.15501441274370467\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9509024976571732\n",
            "\t f1 :  [0.72309247 0.97784403 0.75964719 0.83224309 0.8329387 ]\n",
            "\t average f1 :  0.8251530949674232\n",
            "\t confusion matrix :  [[ 1431   562    51    34   172]\n",
            " [   87 41001    35    20    21]\n",
            " [   37   239   689     7    35]\n",
            " [   39   658     6  1972    15]\n",
            " [  114   236    26    16  1583]]\n",
            "Epoch #13\n",
            "Training..\n",
            "Training loss:  0.08847519644984493\n",
            "Training metrics:\n",
            "\t accuracy :  0.9962872213544656\n",
            "\t f1 :  [0.9711558  0.99930201 0.97498054 0.99676316 0.97607246]\n",
            "\t average f1 :  0.9836547944377058\n",
            "\t confusion matrix :  [[  9562     83     69     21    142]\n",
            " [    62 166792     14      4     17]\n",
            " [    42     26   4384      5     35]\n",
            " [    15     10      2  10932      9]\n",
            " [   134     17     32      5   7975]]\n",
            "Validating..\n",
            "Validation loss:  0.14580912036555155\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9502709530212281\n",
            "\t f1 :  [0.72449483 0.97776453 0.73571024 0.83042656 0.8316725 ]\n",
            "\t average f1 :  0.8200137322320687\n",
            "\t confusion matrix :  [[ 1470   560    43    40   137]\n",
            " [   83 41005    35    24    17]\n",
            " [   72   246   650    11    28]\n",
            " [   39   658     5  1976    12]\n",
            " [  144   242    27    18  1544]]\n",
            "Epoch #14\n",
            "Training..\n",
            "Training loss:  0.07768769562244415\n",
            "Training metrics:\n",
            "\t accuracy :  0.9964743429910736\n",
            "\t f1 :  [0.97186753 0.99932962 0.97813604 0.99690007 0.9772015 ]\n",
            "\t average f1 :  0.9846869522333908\n",
            "\t confusion matrix :  [[  9552     85     54     14    146]\n",
            " [    61 166957     18      4     16]\n",
            " [    46     20   4429      3     28]\n",
            " [    19      6      6  10934      9]\n",
            " [   128     14     23      7   7951]]\n",
            "Validating..\n",
            "Validation loss:  0.14354498790843145\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9485189259666708\n",
            "\t f1 :  [0.68115543 0.97681504 0.75587111 0.82474227 0.83040936]\n",
            "\t average f1 :  0.8137986421549558\n",
            "\t confusion matrix :  [[ 1238   654    68    57   233]\n",
            " [   34 41036    38    21    35]\n",
            " [   21   244   692    11    39]\n",
            " [   22   685     5  1960    18]\n",
            " [   70   237    21    14  1633]]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "## TODO: Re-run with unidirectional LSTMs\n",
        "## Keep other hyperparameters fixed\n",
        "train_val_loop_lstm({\n",
        "    \"bidirectional\": False,\n",
        "    \"batch_size\": 512,\n",
        "    \"d_emb\": 64,\n",
        "    \"d_hidden\": 128,\n",
        "    \"num_epochs\": 15,\n",
        "    \"learning_rate\": 0.005,\n",
        "    \"l2\": 1e-6,\n",
        "})\n",
        "## END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8UChDyKaPBs"
      },
      "source": [
        "### Questions **(2 points)**\n",
        "\n",
        "(a) How does the final performance of LSTMs compare to FFNNs? Is it better? What is a possible explanation?\n",
        "\n",
        "**TODO: Please fill in your answer here**\n",
        "\n",
        "(b) How does bidirectional LSTMs compare to unidirectional LSTMs? Why?\n",
        "\n",
        "**TODO: Please fill in your answer here**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# a:\n",
        "\n",
        "- Accuracy: The BiLSTM model achieved an accuracy of around 95% on the validation set, while the FFNN model achieved around 89% accuracy. This indicates that the BiLSTM model performs better in terms of overall accuracy.\n",
        "- F1 Score: The BiLSTM model achieved an average F1 score of around 77%, while the FFNN model achieved around 66%. The higher F1 score of the BiLSTM model indicates better balance between precision and recall.\n",
        "Loss: The BiLSTM model consistently achieved lower validation loss compared to the FFNN model, indicating better generalization.\n",
        "- Confusion Matrix: The confusion matrix of the BiLSTM model shows better diagonal dominance compared to the FFNN model, indicating better performance in correctly predicting the majority of classes.\n",
        "### Overall, based on the provided outputs, the BiLSTM model outperformed the FFNN model in terms of accuracy, F1 score, and loss. This could be attributed to the ability of LSTMs to capture long-range dependencies in sequential data, which is crucial for NER tasks where context plays a significant role. FFNNs, on the other hand, may struggle to capture such dependencies effectively."
      ],
      "metadata": {
        "id": "zTcaXizmF-97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# b:\n",
        "\n",
        "#### Bidirectional LSTMs (BiLSTMs) are generally more powerful than unidirectional LSTMs (UniLSTMs) because they can capture information from both past and future contexts. This bidirectional nature allows them to better understand the context of a word in a sequence, leading to potentially better performance on tasks that require understanding the entire sequence, such as sequence labeling or sequence classification.\n",
        "\n",
        "#### UniLSTMs, on the other hand, can only capture information from the past, which may limit their ability to capture dependencies that span across long distances in the sequence. However, UniLSTMs are computationally more efficient and simpler to train compared to BiLSTMs.\n",
        "\n",
        "#### In practice, BiLSTMs are often preferred when the task requires understanding context from both directions, such as in natural language processing tasks like named entity recognition, part-of-speech tagging, and machine translation. UniLSTMs are still useful in tasks where future information is not necessary or when computational efficiency is a concern.\n",
        "\n",
        "- Accuracy: BiLSTMs generally achieve higher accuracy compared to UniLSTMs. In your experiment, the accuracy of the BiLSTM model reached around 95% on the validation set, while the UniLSTM model achieved around 94% accuracy.\n",
        "- F1 Score: The F1 score measures the balance between precision and recall. BiLSTMs tend to have higher F1 scores due to their ability to capture information from both directions. In your experiment, the average F1 score for the BiLSTM model was around 77%, while the UniLSTM model achieved around 72%.\n",
        "- Loss: Lower loss indicates better model performance. The BiLSTM model consistently achieved lower validation loss compared to the UniLSTM model, indicating better generalization.\n",
        "- Confusion Matrix: BiLSTMs often result in confusion matrices with better diagonal dominance, indicating that the model is better at correctly predicting the majority of classes."
      ],
      "metadata": {
        "id": "uB5QPDLcFd_-"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}